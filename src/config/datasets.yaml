# PEECOM Multi-Dataset Configuration
# Supports multiple dataset formats and processing pipelines

# Global settings
global:
  base_output_dir: "output"
  log_level: "INFO"

# Dataset-specific configurations
datasets:
  # ZeMA Hydraulic Systems Dataset (text sensors)
  cmohs:
    type: "text_sensors"
    description: "ZeMA Hydraulic Systems with 17 sensors"
    format: "multiple_txt_files_with_profile"

    data:
      dataset_dir: "dataset/cmohs"
      instances: 2205
      cycle_duration: 60
      sensors:
        pressure: 6 # PS1-PS6
        motor_power: 1 # EPS1
        flow: 2 # FS1-FS2
        temperature: 4 # TS1-TS4
        vibration: 1 # VS1
        efficiency: 3 # CE, CP, SE

    targets:
      cooler_condition: 0
      valve_condition: 1
      pump_leakage: 2
      accumulator_pressure: 3
      stable_flag: 4

    preprocessing:
      feature_extraction:
        pressure_sensors: ["mean", "std", "min", "max", "skew", "kurtosis"]
        motor_power: ["mean", "std", "peak_power", "energy"]
        flow_sensors: ["mean", "std", "flow_rate_change"]
        temperature_sensors: ["mean", "std", "trend"]
        vibration: ["rms", "peak", "crest_factor"]
        efficiency: ["mean", "trend"]

      sensor_correction:
        PS4:
          enabled: true
          correction_method: "ensemble"
          reference_sensors: ["PS1", "PS3", "PS5", "PS6"]

  # Equipment Anomaly Detection Dataset (single CSV)
  equipmentad:
    type: "csv"
    description: "Equipment anomaly detection with environmental sensors"
    format: "single_csv"

    data:
      dataset_dir: "dataset/equipmentad"
      target_column: "faulty"
      feature_columns: ["temperature", "pressure", "vibration", "humidity"]
      categorical_columns: ["equipment", "location"]

    targets:
      anomaly: "faulty" # Binary: 0=normal, 1=faulty
      equipment_type: "equipment" # Categorical: Turbine, Compressor, Pump
      location: "location" # Categorical: Atlanta, Chicago, etc.

    preprocessing:
      feature_extraction:
        numerical_features: ["mean", "std", "min", "max"]
        categorical_encoding: "label_encoding"

  # ML Classification Energy Monthly (single CSV)
  mlclassem:
    type: "csv"
    description: "Monthly energy consumption classification"
    format: "single_csv"

    data:
      dataset_dir: "dataset/mlclassem"
      target_column: "Equipment_Status"
      feature_columns:
        [
          "Sensor_Temperature_C",
          "Sensor_Pressure_Bar",
          "Sensor_Vibration_mm_s",
          "Maintenance_Hours",
          "Operational_Hours",
        ]
      categorical_columns: ["Region", "Equipment_Type"]
      date_column: "Date"

    targets:
      status: 0 # Equipment status
      region: 1 # Geographic region
      equipment_type: 2 # Equipment type

    preprocessing:
      feature_extraction:
        numerical_features: ["mean", "std", "min", "max"]
        temporal_features: ["month", "quarter"]

  # Motor Vibration Dataset (multiple CSVs)
  motorvd:
    type: "multi_csv"
    description: "Motor vibration data with multiple conditions"
    format: "multiple_csv_files"

    data:
      dataset_dir: "dataset/motorvd"
      file_limit: 10 # Limit files for processing
      chunk_size: 1000 # Samples per chunk

    targets:
      condition: 0 # Motor condition from filename
      file_id: 1 # File identifier

    preprocessing:
      feature_extraction:
        time_series_features: ["mean", "std", "min", "max", "rms", "peak"]
        window_size: 1000

  # Multivariate Time Series Dataset (text files)
  multivariatetsd:
    type: "text_data"
    description: "NASA turbofan engine degradation"
    format: "space_separated_text"

    data:
      dataset_dir: "dataset/multivariatetsd"
      delimiter: " "
      has_header: false

    targets:
      engine_id: 0
      cycle: 1

    preprocessing:
      feature_extraction:
        sensor_features: ["mean", "std", "trend"]
        sequence_features: ["rolling_mean", "rolling_std"]

  # Sensor Data (mixed format)
  sensord:
    type: "csv"
    description: "Industrial sensor data with machine status"
    format: "mixed_csv_excel"

    data:
      dataset_dir: "dataset/sensord"
      primary_file: "synthetic_industrial_data_with_status.csv"
      target_column: "machine_status"
      feature_columns:
        [
          "sensor_1",
          "sensor_2",
          "sensor_3",
          "sensor_4",
          "sensor_5",
          "sensor_6",
          "sensor_7",
          "sensor_8",
          "sensor_9",
          "sensor_10",
          "sensor_11",
          "sensor_12",
          "sensor_13",
          "sensor_14",
          "sensor_15",
          "sensor_16",
          "sensor_17",
          "sensor_18",
          "sensor_19",
          "sensor_20",
        ]
      temporal_columns: ["timestamp"]

    targets:
      machine_status: "machine_status" # Status: NORMAL, FAULT, WARNING, etc.

    preprocessing:
      feature_extraction:
        numerical_features: ["mean", "std", "min", "max"]
        temporal_features: ["hour", "day_of_week"]

  # Smart Maintenance Dataset
  smartmd:
    type: "csv"
    description: "Smart maintenance dataset with anomaly flags and failure types"
    format: "single_csv"

    data:
      dataset_dir: "dataset/smartmd"
      target_column: "anomaly_flag"
      feature_columns:
        [
          "temperature",
          "vibration",
          "humidity",
          "pressure",
          "energy_consumption",
        ]
      categorical_columns: ["machine_status", "failure_type"]
      temporal_columns: ["timestamp"]

    targets:
      anomaly_flag: "anomaly_flag" # Binary: 0=normal, 1=anomaly
      machine_status: "machine_status" # Status code
      maintenance_required: "maintenance_required" # Binary: 0=no, 1=yes

    preprocessing:
      feature_extraction:
        numerical_features: ["mean", "std", "min", "max"]
        temporal_features: ["hour", "day_of_week"]

  # Time Series Timesteps Dataset
  tsts:
    type: "csv"
    description: "Time series equipment data with maintenance flags"
    format: "structured_csv"

    data:
      dataset_dir: "dataset/tsts"
      processed_file: "processed/processed_data_with_features.csv"
      raw_file: "raw/equipment_data.csv"
      target_column: "Maintenance Required"
      feature_columns:
        ["Temperature (Â°C)", "Vibration (mm/s)", "Pressure (Pa)", "RPM"]
      temporal_columns: ["Timestamp"]

    targets:
      maintenance_required: "Maintenance Required" # Binary: 0=no, 1=yes

    preprocessing:
      feature_extraction:
        time_series_features: ["mean", "std", "trend"]
        temporal_features: ["hour", "day", "month"]

  # ZeMA Test Dataset
  zema_test:
    type: "multi_csv"
    description: "ZeMA test dataset with valve-plate hydraulic pump data"
    format: "multiple_csv_files"

    data:
      dataset_dir: "dataset/zema_test"
      target_column: "stan"
      feature_columns:
        [
          "Pressure - leak line",
          "Temperature - leak line",
          "Pressure - output",
          "Temperature - suction line",
          "Temperature - output",
          "Flow - leak line",
          "Flow - output",
          "Temp. diff",
        ]
      temporal_columns: ["Czas", "Czas2"]

    targets:
      system_status: "stan" # System status (0=normal, other=fault)

    preprocessing:
      feature_extraction:
        hydraulic_features: ["pressure_mean", "flow_mean", "efficiency"]
        temporal_features: ["trend", "variance"]

# Default preprocessing settings (used if not specified per dataset)
default_preprocessing:
  feature_extraction:
    numerical_features: ["mean", "std", "min", "max"]
    categorical_encoding: "label_encoding"

  data_quality:
    max_missing_percentage: 50
    min_samples: 100

  normalization:
    method: "robust"
    per_feature: true

# Training configuration (applies to all datasets)
training:
  epochs: 100
  batch_size: 32
  learning_rate: 0.001
  optimizer: "adam"
  early_stopping_patience: 10

  splits:
    train: 0.7
    val: 0.15
    test: 0.15

# Output configuration
output:
  base_dir: "output"
  subdirs:
    processed_data: "processed_data"
    models: "models"
    logs: "logs"
    analysis: "analysis"
    figures: "figures"
    reports: "reports"

  save_formats: ["csv", "joblib"]

# Logging
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: true
  console: true
